#' Fit local southern sizing model
#' @description Fits a series of 7 linear models necessary to use the local southern method
#'    of sizing, utilized by programs such as peak scanner. The local southern method sizes
#'    an unknown fragment by first computing 2 linear models. The first includes 2 standard points
#'    below the unknown fragment and one point above the unknown fragment. The second includes
#'    one point below the unknown fragment and two points above. Predictions from each model are
#'    then averaged to give the final size prediction.
#' @param std.peaks List of standard peak tables generated by get.std.peak
#' @return Returns a list of nested dataframes containing seven models for each data file. Each
#'    model is based on 3 datapoints. This will by used by apply.size function to finish the
#'    local southern sizing method.
#' @seealso \code{\link{get.std.peak, apply.size}}
#' @export
get.models<-function(std.peaks){
  map(std.peaks, function(x) x[c(1,2,3,
                                 2,3,4,
                                 3,4,5,
                                 4,5,6,
                                 5,6,7,
                                 6,7,8,
                                 7,8,9),] %>%
        mutate(model.group = c(rep(1,3),
                               rep(2,3),
                               rep(3,3),
                               rep(4,3),
                               rep(5,3),
                               rep(6,3),
                               rep(7,3))) %>%
        group_by(model.group) %>%
        nest()) %>%
    map(function(x) mutate(x, mod=map(x$data,function(y) lm(std~position,data=y))))
}

#' Apply the local southern sizing method
#' @description This function completes the local southern sizing method. See get.models for a description.
#'   First predictions for every data point for each of the 7 models are made.
#'   After that the appropriate rowwise averages of predictions are made using matricies.
#'   Finally the sizing is determined based on where each datapoint falls with respect to the standards.
#' @param data List of data tables genereated by read.data
#' @param models List of nested models generated by get.models
#' @param std.peaks List of standard peak tables generated by get.std.peak
#' @return The list of input data tables is returned with additional columns for model predictions,
#'    averages and finally the size in basepairs (column size.bps)
#' @seealso \code{\link{get.models, precompute.avgs}}
#' @export
apply.size<-function(data,models,std.peaks){
    data %>%
    map2(.,map2(models,.,function(z,w) predict(z$mod[[1]],newdata=w)), function(x,y) mutate(x, pred.lm.1 = y)) %>%
    map2(.,map2(models,.,function(z,w) predict(z$mod[[2]],newdata=w)), function(x,y) mutate(x, pred.lm.2 = y)) %>%
    map2(.,map2(models,.,function(z,w) predict(z$mod[[3]],newdata=w)), function(x,y) mutate(x, pred.lm.3 = y)) %>%
    map2(.,map2(models,.,function(z,w) predict(z$mod[[4]],newdata=w)), function(x,y) mutate(x, pred.lm.4 = y)) %>%
    map2(.,map2(models,.,function(z,w) predict(z$mod[[5]],newdata=w)), function(x,y) mutate(x, pred.lm.5 = y)) %>%
    map2(.,map2(models,.,function(z,w) predict(z$mod[[6]],newdata=w)), function(x,y) mutate(x, pred.lm.6 = y)) %>%
    map2(.,map2(models,.,function(z,w) predict(z$mod[[7]],newdata=w)), function(x,y) mutate(x, pred.lm.7 = y)) %>%
    map(.,precompute.avgs) %>%
    map2(.,std.peaks, function(x,y) mutate(x, size.bps = case_when(position <= y$position[2] ~ pred.lm.1,
                                                                   position > y$position[2] & position <= y$position[3] ~ avg1,
                                                                   position > y$position[3] & position <= y$position[4] ~ avg2,
                                                                   position > y$position[4] & position <= y$position[5] ~ avg3,
                                                                   position > y$position[5] & position <= y$position[6] ~ avg4,
                                                                   position > y$position[6] & position <= y$position[7] ~ avg5,
                                                                   position > y$position[7] & position <= y$position[8] ~ avg6,
                                                                   position > y$position[8] ~ pred.lm.7
    )))
}

#' Rowwise averages of model predictions
#' @description This function is used by apply.size to get the averages needed for local southern sizing.
#'    It uses matrix algebra (the rowMeans function from the Matrix package), which is much much
#'    faster than doing a rowwise operation with dplyr.
#' @param data.subset The data with model predictions added.
#' @return The list of input data tables is returned with additional columns for model prediction averages.
#' @seealso \code{\link{get.models,apply.size}}
#' @export
precompute.avgs<-function(data.subset){
  mutate(data.subset,
         avg1 = rowMeans(matrix(c(pred.lm.1,pred.lm.2),ncol=2)),
         avg2 = rowMeans(matrix(c(pred.lm.2,pred.lm.3),ncol=2)),
         avg3 = rowMeans(matrix(c(pred.lm.3,pred.lm.4),ncol=2)),
         avg4 = rowMeans(matrix(c(pred.lm.4,pred.lm.5),ncol=2)),
         avg5 = rowMeans(matrix(c(pred.lm.5,pred.lm.6),ncol=2)),
         avg6 = rowMeans(matrix(c(pred.lm.6,pred.lm.7),ncol=2))
  )
}

#' Convert peaks start and end points to base-pair sizing units.
#' @description This is a simple function to convert the start and end values of a peak table to base-pair units.
#' @param data List of data tables genereated by read.data and modified by apply.size.
#' @param peaks List of peak tables that you want to convert the start and end values to basepairs
#' @return The input peak table is returned with added columns for the base pair sized start and end values.
#' @seealso \code{\link{get.models, precompute.avgs}}
#' @export
convert.start.end<-function(peaks,data){
  map(data,function(x) select(x,position,size.bps)) %>%
    map2(peaks,.,function(x,y) mutate(x,start.bps = unlist(select(filter(y,position %in% x$start),size.bps)),
                                      end.bps = unlist(select(filter(y,position %in% x$end),size.bps))))
}

#' Filter size
#' @description This is a simple function to filter the sizes less than zero bp.
#' @param data List of data tables genereated by read.data and modified by apply.size.
#' @return List of Filtered input data
#' @seealso \code{\link{get.models, precompute.avgs}}
filter.size<-function(data){
  map(data,function(x) filter(x,size.bps >= 0))
}
